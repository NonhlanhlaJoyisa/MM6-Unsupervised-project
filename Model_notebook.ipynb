{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div style=\"font-size: 34px\"> \n",
    "<font color='blue'> <b>Anime Recommender System Project 2024 competition</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## CONTENTS\n",
    "* <b>[1. Project Overview](#chapter1)\n",
    "    * [1.1. Aim](#sub_section_1_1_2)\n",
    "    * [1.2. Objectives](#section_1_1_3)\n",
    "* <b>[2. Importing Packages](#chapter2)\n",
    "* <b>[3. Data Preprocessing](#chapter3)\n",
    "* <b>[4. Data Cleaning](#chapter4)\n",
    "* <b>[5. Exploratory Data Analysis](#chapter5)\n",
    "* <b>[6. Modeling](#chapter7)\n",
    "* <b>[7. Conclusions](#chapter8)\n",
    "* <b>[8. Recomendations](#chapter9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Project Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Importing Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhtml\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVD, KNNBasic, BaselineOnly, Dataset, Reader\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_validate\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import re\n",
    "from html import unescape\n",
    "import html\n",
    "import pickle\n",
    "from surprise import SVD, KNNBasic, BaselineOnly, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Data Preprocessing** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Data Overview <a class=\"anchor\" id=\"dataset\"></a>\n",
    "\n",
    "This dataset contains information on anime content (movies, television series, music, specials, OVA, and ONA*), split between a file related to the titles (anime.csv) and one related to user ratings of the titles (training.csv). The test.csv file will be used to create the rating predictions and must be submitted for grading. The submissions.csv file illustrates the expected format of submissions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Data Loading <a class=\"anchor\" id=\"data preprocessing\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the anime.csv file into a DataFrame\n",
    "anime_df = pd.read_csv('anime.csv')\n",
    "print(anime_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the train.zip (csv) file into a DataFrame\n",
    "train_df = pd.read_csv('train.zip')\n",
    "print(train_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the test.csv file into a DataFrame\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print(test_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Exploring the Dataset\n",
    "\n",
    "In this section, we explore the dataset to understand its structure and the information it contains. The code snippets below provide an overview of the dataset's shape, the number of columns, and metadata information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the dataset\n",
    "print(anime_df.shape)\n",
    "\n",
    "# information about metadata\n",
    "anime_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the dataset\n",
    "print(train_df.shape)\n",
    "\n",
    "# information about metadata\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the dataset\n",
    "print(test_df.shape)\n",
    "\n",
    "# information about metadata\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Cleaning** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Missing values <a class=\"anchor\" id=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in anime_df:\")\n",
    "print(anime_df.isnull().sum())\n",
    "print(\"\\nMissing values in train_df:\")\n",
    "print(train_df.isnull().sum())\n",
    "print(\"\\nMissing values in test_df:\")\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Drop Duplicates <a class=\"anchor\" id=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates if any\n",
    "anime_df.drop_duplicates(inplace=True)\n",
    "train_df.drop_duplicates(inplace=True)\n",
    "test_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Cleaning anime_df <a class=\"anchor\" id=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean anime_df\n",
    "def clean_anime_df(df):\n",
    "    # Ensure anime_id is unique and non-null\n",
    "    assert df['anime_id'].is_unique, \"anime_id column has duplicate values.\"\n",
    "    assert df['anime_id'].notnull().all(), \"anime_id column has null values.\"\n",
    "    df['anime_id'] = df['anime_id'].astype(int)\n",
    "\n",
    "    # Function to clean names and unescape HTML entities\n",
    "    def clean_name(name):\n",
    "        name = unescape(name)  # Convert HTML entities to characters\n",
    "        name = name.lower().strip()  # Convert to lowercase and strip whitespace\n",
    "        # Replace specific known HTML entities and problematic characters\n",
    "        name = name.replace(\"&#039;\", \"'\").replace(\"Â°\", \"\")\n",
    "        # Remove any other unwanted special characters but allow meaningful ones\n",
    "        name = re.sub(r'[^a-zA-Z0-9\\s\\.\\,\\-\\&\\:\\;\\']', '', name)\n",
    "        return name\n",
    "\n",
    "    # Apply the cleaning function to the 'name' column\n",
    "    df['name'] = df['name'].apply(clean_name)\n",
    "\n",
    "    # Handle missing values in 'genre' and split into lists\n",
    "    df['genre'] = df['genre'].fillna('')\n",
    "    df['genre'] = df['genre'].apply(lambda x: x.split(', '))\n",
    "\n",
    "    # Function to standardize genre lists\n",
    "    def standardize_genres(genres):\n",
    "        return [genre.strip().lower() for genre in genres]\n",
    "\n",
    "    # Apply the function to genre_list column\n",
    "    df['genre'] = df['genre'].apply(standardize_genres)\n",
    "\n",
    "    # Standardize the 'type' column\n",
    "    df['type'] = df['type'].str.lower().str.strip().fillna('unknown')\n",
    "\n",
    "    # Ensure episodes is numeric and handle missing values\n",
    "    df['episodes'] = pd.to_numeric(df['episodes'], errors='coerce').fillna(-1).astype(int)\n",
    "\n",
    "    # Ensure rating is numeric (should remain float) and handle missing values\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce').fillna(-1.0)\n",
    "\n",
    "    # Ensure members is numeric and handle missing values\n",
    "    df['members'] = pd.to_numeric(df['members'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframes\n",
    "anime_df = clean_anime_df(anime_df)\n",
    "# Example of converting genre to a string for TF-IDF\n",
    "anime_df['genre_str'] = anime_df['genre'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Encoding type variable\n",
    "anime_df['type_encoded'] = anime_df['type'].astype('category').cat.codes\n",
    "\n",
    "# Display the first few rows of the cleaned dataframes for verification\n",
    "print(f'Cleaned anime_df:\\n{anime_df.head()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4. Cleaning train data <a class=\"anchor\" id=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to clean train_df\n",
    "def clean_train_df(df):\n",
    "    # Ensure user_id and anime_id are non-null and numeric\n",
    "    df = df.dropna(subset=['user_id', 'anime_id'])\n",
    "    df['user_id'] = pd.to_numeric(df['user_id'], errors='coerce')\n",
    "    df['anime_id'] = pd.to_numeric(df['anime_id'], errors='coerce')\n",
    "    \n",
    "    # Handle ratings: ensure they are integers and within a valid range\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "    \n",
    "    # Option 1: Filter out rows where rating is -1, ensuring rating remains an integer\n",
    "    df = df[df['rating'] != -1]\n",
    "    \n",
    "    # Remove remaining rows with NaN values that could not be converted\n",
    "    df.dropna(subset=['user_id', 'anime_id', 'rating'], inplace=True)\n",
    "\n",
    "    # Ensure the remaining ratings are within the valid range\n",
    "    df = df[(df['rating'] >= 1) & (df['rating'] <= 10)]\n",
    "    df['rating'] = df['rating'].astype(int)  # Ensure rating column is of integer type\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframes\n",
    "train_df = clean_train_df(train_df)\n",
    "\n",
    "# Display the first few rows of the cleaned dataframes for verification\n",
    "print(f'Cleaned train_df:\\n{train_df.head()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5. Cleaning test data <a class=\"anchor\" id=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to clean test_df\n",
    "def clean_test_df(df):\n",
    "    # Ensure user_id and anime_id are non-null and numeric\n",
    "    df = df.dropna(subset=['user_id', 'anime_id'])\n",
    "    df['user_id'] = pd.to_numeric(df['user_id'], errors='coerce')\n",
    "    df['anime_id'] = pd.to_numeric(df['anime_id'], errors='coerce')\n",
    "    \n",
    "    # Remove rows with NaN values that could not be converted\n",
    "    df.dropna(subset=['user_id', 'anime_id'], inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframes\n",
    "test_df = clean_test_df(test_df)\n",
    "\n",
    "# Display the first few rows of the cleaned dataframes for verification\n",
    "print(f'Cleaned test_df:\\n{test_df.head()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Models**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **6.1 Collaborative Filtering Model (SVD)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 50% of the training data\n",
    "train_df = train_df.sample(frac=0.5, random_state=42)\n",
    "\n",
    "# Example of converting genre to a string for TF-IDF\n",
    "anime_df['genre_str'] = anime_df['genre'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Encoding type variable\n",
    "anime_df['type_encoded'] = anime_df['type'].astype('category').cat.codes\n",
    "\n",
    "# Data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, validation_set = train_test_split(train_df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD, NMF, accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Prepare the data for Surprise\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(train_set[['user_id', 'anime_id', 'rating']], reader)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "svd = SVD()\n",
    "nmf = NMF()\n",
    "\n",
    "# Function to train, evaluate, and log models using MLflow\n",
    "def train_evaluate_log(model, model_name):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Train the model\n",
    "        model.fit(trainset)\n",
    "\n",
    "        # Cross-validate the model\n",
    "        cv_results = cross_validate(model, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "        mean_rmse = np.mean(cv_results['test_rmse'])\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        predictions = model.test(testset)\n",
    "        test_rmse = accuracy.rmse(predictions, verbose=True)\n",
    "\n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_metric(\"cv_rmse\", mean_rmse)\n",
    "        mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "        print(f'{model_name} Model logged with CV RMSE: {mean_rmse} and Test RMSE: {test_rmse}')\n",
    "\n",
    "# Train, evaluate, and log SVD and NMF models\n",
    "train_evaluate_log(svd, \"SVD\")\n",
    "train_evaluate_log(nmf, \"NMF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# svd has the best performance (based on MLflow tracking results)\n",
    "best_model = svd\n",
    "\n",
    "# Save the best model as a pickle file\n",
    "with open('best_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(\"Best model has been pickled successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2 Content-Based Filtering Model**\n",
    "\n",
    "* **Content-Based Filtering using TF-IDF and Cosine Similarity:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Fit TF-IDF vectorizer on genres\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(anime_df['genre_str'])\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get content-based recommendations\n",
    "def get_content_based_recommendations(anime_id, cosine_sim=cosine_sim):\n",
    "    idx = anime_df.index[anime_df['anime_id'] == anime_id].tolist()[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]  # Get top 10 recommendations\n",
    "    anime_indices = [i[0] for i in sim_scores]\n",
    "    return anime_df.iloc[anime_indices]\n",
    "\n",
    "# Example of getting content-based recommendations\n",
    "recommendations = get_content_based_recommendations(anime_id=1)\n",
    "print(recommendations[['anime_id', 'name', 'genre_str']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.3 Hybrid Model**\n",
    "* **Combining SVD predictions and content-based similarity scores:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recommendation(user_id, anime_id, svd_model, cosine_sim=cosine_sim, threshold=5):\n",
    "    svd_prediction = svd_model.predict(user_id, anime_id).est\n",
    "    if svd_prediction >= threshold:\n",
    "        return svd_prediction\n",
    "    else:\n",
    "        content_based_recommendations = get_content_based_recommendations(anime_id, cosine_sim)\n",
    "        return content_based_recommendations['rating'].mean()  # Return the average rating of top content-based recommendations\n",
    "\n",
    "# Example of hybrid recommendation\n",
    "hybrid_rating = hybrid_recommendation(user_id=1, anime_id=1, svd_model=svd)\n",
    "print(f\"Hybrid Rating: {hybrid_rating}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Submission Preparation\n",
    "Preparing the Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict ratings for the test set using the hybrid model\n",
    "predicted_ratings = []\n",
    "for i, row in test_df.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    anime_id = row['anime_id']\n",
    "    hybrid_rating = hybrid_recommendation(user_id, anime_id, svd_model)\n",
    "    predicted_ratings.append(hybrid_rating)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission_df = test_df.copy()\n",
    "submission_df['rating'] = pd.Series(predicted_ratings, dtype=float)\n",
    "submission_df['ID'] = submission_df.apply(lambda x: f\"{int(x['user_id'])}_{int(x['anime_id'])}\", axis=1)\n",
    "submission_df = submission_df[['ID', 'rating']]\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv('submission_hybrid.csv', index=False, float_format='%.5f')\n",
    "print(f'Submission file created successfully.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Hyper parameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "# Prepare the data for Surprise\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(train_df[['user_id', 'anime_id', 'rating']], reader)\n",
    "\n",
    "# Use 50% of the training data\n",
    "train_df = train_df.sample(frac=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Parameter grid for GridSearchCV\n",
    "param_grid_svd = {\n",
    "    'n_factors': [50, 100, 150],\n",
    "    'n_epochs': [20, 30, 40],\n",
    "    'lr_all': [0.002, 0.005, 0.01],\n",
    "    'reg_all': [0.02, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "# Initialize MLflow experiment\n",
    "mlflow.set_experiment(\"SVD Hyperparameter Tuning\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"GridSearch_SVD\"):\n",
    "    # GridSearchCV for SVD\n",
    "    gs_svd = GridSearchCV(SVD, param_grid_svd, measures=['rmse'], cv=3, n_jobs=-1, joblib_verbose=2)\n",
    "    gs_svd.fit(data)\n",
    "\n",
    "    # Log best parameters and RMSE\n",
    "    mlflow.log_params(gs_svd.best_params['rmse'])\n",
    "    mlflow.log_metric(\"Best RMSE\", gs_svd.best_score['rmse'])\n",
    "\n",
    "    print(\"Best SVD parameters (GridSearchCV): \", gs_svd.best_params['rmse'])\n",
    "    print(\"Best SVD RMSE (GridSearchCV): \", gs_svd.best_score['rmse'])\n",
    "\n",
    "    # Train the best SVD model\n",
    "    best_svd = SVD(**gs_svd.best_params['rmse'])\n",
    "    best_svd.fit(trainset)\n",
    "\n",
    "    # Evaluate the best SVD model with cross-validation\n",
    "    cv_results = cross_validate(best_svd, data, measures=['RMSE'], cv=3, verbose=True)\n",
    "\n",
    "    # Log cross-validation results\n",
    "    for key, values in cv_results.items():\n",
    "        mlflow.log_metric(key, np.mean(values))\n",
    "\n",
    "    # Evaluate the best SVD model on the test set\n",
    "    predictions = best_svd.test(testset)\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    mlflow.log_metric(\"Test RMSE\", rmse)\n",
    "    print(f'Best SVD Test RMSE: {rmse}')\n",
    "\n",
    "    # Save the best model as a pickled file\n",
    "    model_filename = \"best_svd_model.pkl\"\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(best_svd, f)\n",
    "    mlflow.log_artifact(model_filename)\n",
    "\n",
    "    # Predict ratings for each entry in test_df using the trained best SVD model\n",
    "    predicted_ratings = []\n",
    "    for i, row in test_df.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        anime_id = row['anime_id']\n",
    "        \n",
    "        # Ensure the prediction is within the valid range\n",
    "        try:\n",
    "            pred = best_svd.predict(user_id, anime_id).est\n",
    "            pred = max(1.0, min(pred, 10.0))  # Ensure the prediction is within the rating scale\n",
    "        except ValueError as e:\n",
    "            print(f\"Error predicting for user_id: {user_id} and anime_id: {anime_id} - {e}\")\n",
    "            pred = np.mean(train_df['rating'])  # Use the mean rating as a default value\n",
    "\n",
    "        predicted_ratings.append(pred)\n",
    "\n",
    "    # Create a copy of test_df to hold the results\n",
    "    results_df = test_df.copy()\n",
    "\n",
    "    # Add predictions to the test dataframe\n",
    "    results_df['rating'] = pd.Series(predicted_ratings, dtype=float)\n",
    "\n",
    "    # Ensure no NaN values in predictions and update the column directly\n",
    "    results_df['rating'] = results_df['rating'].fillna(np.mean(train_df['rating']))\n",
    "\n",
    "    # Create the ID column by concatenating user_id and anime_id\n",
    "    results_df['ID'] = results_df.apply(lambda x: f\"{int(x['user_id'])}_{int(x['anime_id'])}\", axis=1)\n",
    "\n",
    "    # Prepare the submission file\n",
    "    submission_df = results_df[['ID', 'rating']]\n",
    "\n",
    "    # Debugging: Ensure predictions and format look correct\n",
    "    print(f\"Sample predictions with ID and rating for SVD:\")\n",
    "    print(submission_df.head())\n",
    "\n",
    "    # Save the submission file ensuring float format\n",
    "    submission_file = \"submission_svd.csv\"\n",
    "    submission_df.to_csv(submission_file, index=False, float_format='%.5f')\n",
    "    print(f'Submission file {submission_file} created successfully.')\n",
    "\n",
    "    # Log the submission file\n",
    "    mlflow.log_artifact(submission_file)\n",
    "\n",
    "mlflow.end_run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVD_rmse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Prepare data for plotting\u001b[39;00m\n\u001b[0;32m      2\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNMF\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m rmse_values \u001b[38;5;241m=\u001b[39m [SVD_rmse, baseline_rmse, NMF_rmse]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for plotting\u001b[39;00m\n\u001b[0;32m      6\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m: models,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: rmse_values\n\u001b[0;32m      9\u001b[0m })\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SVD_rmse' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare data for plotting\n",
    "models = ['SVD', 'Baseline', 'NMF']\n",
    "rmse_values = [SVD_rmse, baseline_rmse, NMF_rmse]\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'RMSE': rmse_values\n",
    "})\n",
    "\n",
    "# Plot the RMSE values\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='Model', y='RMSE', data=results_df, palette='coolwarm')\n",
    "\n",
    "# Set y-axis limit to start from 1 and extend a bit beyond the max RMSE\n",
    "plt.ylim(1, max(rmse_values) * 1.1)\n",
    "\n",
    "# Add data labels to the bars\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height:.2f}',\n",
    "                (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center', va='center',\n",
    "                xytext=(0, 5),  # 5 points vertical offset\n",
    "                textcoords='offset points')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Comparison of RMSE Values for Different Models')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "# Show the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
